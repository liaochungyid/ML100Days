{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:349: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 96)        83040     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 15, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 192)       331968    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 192)         331968    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                94090     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,092,874\n",
      "Trainable params: 1,092,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 模仿 STRIVING FOR SIMPLICITY: THE ALL CONVOLUTIONAL NET \n",
    "# (Author: Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, Martin Riedmiller)\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import os\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "data_gen = ImageDataGenerator(rotation_range=20,width_shift_range=0.2,height_shift_range=0.2,\n",
    "                              featurewise_std_normalization=True,horizontal_flip=True)\n",
    "data_gen.fit(x_train)\n",
    "\n",
    "\n",
    "# pooling 用 conv2d strides=2代替\n",
    "# 只做兩組，電腦無GPU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(96, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(96, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(96, (3, 3), strides=2))\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(192, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(192, (3, 3), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "195/195 [==============================] - 592s 3s/step - loss: 1.7007 - accuracy: 0.3747 - val_loss: 64.6462 - val_accuracy: 0.2847\n",
      "Epoch 2/10\n",
      "195/195 [==============================] - 596s 3s/step - loss: 1.3413 - accuracy: 0.5160 - val_loss: 66.5711 - val_accuracy: 0.2856\n",
      "Epoch 3/10\n",
      "195/195 [==============================] - 596s 3s/step - loss: 1.1611 - accuracy: 0.5865 - val_loss: 74.6497 - val_accuracy: 0.2892\n",
      "Epoch 4/10\n",
      "195/195 [==============================] - 594s 3s/step - loss: 1.0243 - accuracy: 0.6389 - val_loss: 68.8279 - val_accuracy: 0.3105\n",
      "Epoch 5/10\n",
      "195/195 [==============================] - 604s 3s/step - loss: 0.9320 - accuracy: 0.6759 - val_loss: 63.5670 - val_accuracy: 0.3600\n",
      "Epoch 6/10\n",
      "195/195 [==============================] - 601s 3s/step - loss: 0.8575 - accuracy: 0.7016 - val_loss: 66.3888 - val_accuracy: 0.3716\n",
      "Epoch 7/10\n",
      "195/195 [==============================] - 603s 3s/step - loss: 0.8037 - accuracy: 0.7208 - val_loss: 60.6344 - val_accuracy: 0.4603\n",
      "Epoch 8/10\n",
      "195/195 [==============================] - 603s 3s/step - loss: 0.7673 - accuracy: 0.7350 - val_loss: 59.8410 - val_accuracy: 0.4037\n",
      "Epoch 9/10\n",
      "195/195 [==============================] - 599s 3s/step - loss: 0.7275 - accuracy: 0.7475 - val_loss: 67.1910 - val_accuracy: 0.3946\n",
      "Epoch 10/10\n",
      "195/195 [==============================] - 600s 3s/step - loss: 0.6955 - accuracy: 0.7592 - val_loss: 58.5609 - val_accuracy: 0.4564\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 58.5609 - accuracy: 0.4564\n",
      "Test loss: 58.560874938964844\n",
      "Test accuracy: 0.4564000070095062\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(data_gen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train) // batch_size,\n",
    "                    epochs=epochs,verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
